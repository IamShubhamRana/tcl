{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamShubhamRana/tcl/blob/main/Answer_Sheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EE 599 Reading Assignment \\# 1:\n",
        "You can access paper using this [link](https://courses.cs.washington.edu/courses/cse550/21au/papers/CSE550.Eyeriss.pdf), do not re-distribute the paper."
      ],
      "metadata": {
        "id": "JA0rETRQZBON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1: (1 Point)\n",
        "\n",
        "**Disallowed** list:\n",
        "- You **MAY NOT** collaborate with anyone else on this assignment. This means you cannot talk to anyone else about the assignment until after deadline.\n",
        "- You **MAY NOT** use ChatGPT and services like that\n",
        "\n",
        "**Allowed** list:\n",
        "- Notes including any slides from the class\n",
        "- The textbooks\n",
        "- The given paper"
      ],
      "metadata": {
        "id": "s-HWWv6kaxrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A1:\n",
        "\n",
        "I affirm I have read these exam rules and will follow them. Failure to do so may subject me to sanctions including an F in the course.\n",
        "\n",
        "**Type your full name to affirm you have read the above statement:**\n"
      ],
      "metadata": {
        "id": "Pz0uD-nHbHuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHUBHAM RANA"
      ],
      "metadata": {
        "id": "4hvshs49tI1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## Q2.1 Summary (24 Points):\n",
        "\n",
        "Summarize the main objectives and contributions of the paper."
      ],
      "metadata": {
        "id": "XzNWLVCLbcjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A2.1:"
      ],
      "metadata": {
        "id": "0j5A4_Zfbpra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.2 Comprehension (15 Points):\n",
        "- What problem is the paper addressing?\n",
        "- How does the Eyeriss architecture differ from other architectures you are familiar with?"
      ],
      "metadata": {
        "id": "IE2n5UQHbuZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A2.2:\n",
        "\n",
        "The paper describes that the current state-of-the-art CNNs need to perform billions of operations in a single inference pass. These Data intensive computations would cause significant data movement which require more energy than the computations itself. It mentions that the data movement must be optimized in order to achieve enerfy efficiency especially when working with high-dimensional convolutions. Hence they propose a compute scheme that can support a highly parallel compute paradigm while optimizing the energy cost of data movement from both on-chip and off-chip.<br>\n",
        "<br>\n",
        "Eyeriss differs from other architectures as rather than using the typical Input/Weight/Output Stationary Dataflow. It proposes a Row Stationary dataflow which maximizes both high parallelism and energy-efficient data transfer. Also Eyeriss supports this RS Dataflow using a Network on Chip (NoC) architecture that blends multicast and point-to-point single cycle data delivery. Eyeriss architecture also includes the ability to capatilize on the sparsity of data in CNNs and further improve energy efficiency by using Run-Length Compression (RLC) and PE data gating algorithms."
      ],
      "metadata": {
        "id": "9O7k2DbXcNp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.3 Technical Deep Dive (15 Points):\n",
        "- Describe the spatial architecture of Eyeriss in your own words.\n",
        "- How does the Eyeriss architecture optimize energy efficiency in dataflow for CNNs?\n",
        "- What are the main challenges in designing an energy-efficient architecture for CNNs, and how does Eyeriss tackle these challenges?"
      ],
      "metadata": {
        "id": "PnzcxvhWckY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.3:\n",
        "The spatial architecture consists of 168 Processing elements (PEs) to build a multilevel memory hierarchy that has four levels. By leveraging low-cost memory levels to reduce access to high-cost levels, such as off-chip DRAM, this design improves data mobility. They have a large on-chip global buffer (GLB) which acts like a central storage unit and stores ifmaps, filters and psums. GLB also need lower energy per access compared to the DRAM. The architecture is rounded off with the NoC that interconnects the PEs, GLB and memory components. This is custom designed to efficiently handle data delivery thus reducing data movement overhead. <br>\n",
        "<br> Eyeriss Architecture optimizes energy efficiency in dataflow for CNNs using the below methods:<br>\n",
        "(1) *Data Reuse:* By storing the data in the GLB we can reuse the data for different processing passes and minimize the number of off-chip data accesses. Also in the paper they have explained the data reuse in three forms of: Convolutional, Filter and Ifmap Reuse.<br>\n",
        "(2) *Data Gating Logic:* They implement this logic to exploit zeros in the ifmaps. When zero values are detected, the logic prevents the unnecesary reading of filter weights and prevents MAC datapath from switching.<br>\n",
        "(3) *Reconfiguration:* Batches of ifmaps for the same layer can be processed sequentially without further reconfiguration of the chip.<br>\n",
        "(4) *PE Array:* The spatial parallelism created by the PE array helps in ifmap reuse and psum accumulation opportunities.<br>\n",
        "<br> The main challenges in designing an energy-efficient architecture for CNNs are:<br>\n",
        "(1) *Data Movement:* Moving data between on-chip and off-chip memory is energy intensive. Eyeriss solves this by the reuse and accumulation of data within a PE set which reduces the access to the GLB and DRAM. <br>\n",
        "(2) *Computation:* There are huge numbers of parameters and layers in a CNN. Performing such a humongous number of MAC operations consume a large amount of energy. Eyeriss solves this by using the PE array which perform computations in parallel that enable data reuse and also by gating the logic to skip operations on zeros."
      ],
      "metadata": {
        "id": "sv3rFNjpcuID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.4 Evaluation (15 Points):\n",
        "- What were the key results or findings of the paper? Were they compelling?\n",
        "- How do the authors validate their claims or results? Are there any weaknesses in their methodology?"
      ],
      "metadata": {
        "id": "HRBvFutTc2uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.4:\n",
        "The focus of the paper is on energy efficiency. Eyeriss describes its methodology and architecture in order to minimize energy for both computation and data movement for CNNs. The results shown in the paper for a given network of AlexNet we are able to decrease the power consumption as we go into deeper layers with the help of data gating. The measured efficiency is calculated to be 83.1 GMACs/W for 1V and 122.8 GMACs/W at 0.82V thus validating that Eyeriss performs a significant number of MAC operations per watt of power consumed. Also, the results validate the concept of data reuse. As, in power consumption spads consumes the second highest after the clock network. Showing that the Row stationary method resuses data locally for reducing DRAM accesses.<br>\n",
        "Yes the results were compelling as they were abel to produce the results in line with their hypothesis. Also, they took a holistic approach by considering both the computation and data movement aspects and exploring the opportunities to reduce the number of Operations by skipping on zeros. They also described the Row stationary Method proposed in paper in 1D, 2D and beyond which is necessary as limiting the method to a particular dimenssional operation significantly reduces the usefulness in real world scenarios.<br>\n",
        "\n",
        "<br> The authors validated their claims by running several performance measurements on them. They benchmarked the chip performance by using 2 CNNs namely AlexNet and VGG-16. They also implemented the given design on 65nm-CMOS and measured its peak throughput (33.6 GMAC/s) at 1V with a 200Mhz clock.\n",
        "Few of the Weakness that can be pointed out in their methodology:<br>\n",
        "(1) *Technology:* The hardware implementaion of Eyeriss is done on 65-nm CMOS technology. In current world scenario that is out-of-date, we need to evaluate Eyeriss across 7nm, 5nm or below nodes. This is due to the fact that as we go into lower technolgies the dynamic power(switching) becomes a lower factor of overall power but the leakage power (off state current from every device) becomes a major contributor. Which is just opposite to the Eyeriss implementation as we reduce the number of activity but increase the number of devices due to the big PE array and the GLB connected through NoC. This might not give similar benefits in lower nodes. As this increase in number of transistors will hurt us while the power due to the activity will not be a big factor like before.<br>\n",
        "(2) *Benchmarking:* The results shown are from 2 CNN Models: Alexnet and VGG-16. Even though they are widely used it represents only a shallow set. The result might not be representative of all CNN Models. Different CNN Models might have varying shapes and computation requirements thus the results outcome might vary when applied to other models.<br>\n",
        "(3) *Real World Workloads:* The performance is provided using benchmarks and not real world workloads. Running real-world applications or workloads which mimic them would have given us a even more confidence on the given approach."
      ],
      "metadata": {
        "id": "xKUL8nhTdNLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.5 Contextual Understanding (10 Points):\n",
        "- How does this work fit into the larger context of neural network architectures and energy efficiency?\n",
        "- Can the principles of Eyeriss be applied to other deep learning architectures beyond CNNs?\n"
      ],
      "metadata": {
        "id": "Fp_FV2bzdV4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.5:\n",
        "Context with Neural Network Architecture and Energy Efficiency: <br>\n",
        "(1) *Data Reuse and Dataflow:* It provies us a new method of Row Stationary Dataflow which aims to reduce the data movement between on chip and off chip memory. This concept can be used in other architectures or approaches in order to increase the energy efficieny by building on this concept.<br>\n",
        "(2) *Specialization:* Earlier GPUs were used for the processing and doing convolution in networks. While they are good for general workload they might not be better suited for unique dataflow or computation patterns like in CNNs. Thus we might need some other alternatives in those scenarios. Eyeriss gives a good example by matching its architecture to the requirement of CNNs.<br>\n",
        "(3) *Hardware Accelerators:* Eyeriss falls in line with the current surge in the use of hardware accelrators for CNNs. As Machine Learning and AI are the hot topics of the hour, particulary CNNs, they are being infused in all applications even in your latest mobile phones. Hence, to incorporate these and still deliver high performance with optimizing energy consumption hardware accelerators are needed and Eyeriss is a good example for that. <br>\n",
        "<br> Yes principles of Eyeriss can be applied to other deep learning architectures beyond CNNs. Eyeriss was specifically designed to accelerate CNNs, we can extend it's design principles to other deep learning architectures which have their own unique characteristics and requirements although with the appropriate adaptations and trade-offs. Those principles can be:<br>\n",
        "(1) *Data Reuse:* The principle of data re-use and minimizing off-chip memory accesses. Many deep learning models depend on reusing intermediate results just like CNN. Hence, we can look into optimizing data locality and reducing memory transfers.<br>\n",
        "(2) *Spatial Architecture:* Eyeriss provided the spatial architecture of PE array, GLB and the NoC. For a given deep learning architecture we can look into tweaking the PEs and the dataflow based on that architecture's requirements.<br>\n",
        "(3) *Energy Efficiency:* Reducing power consumption and improving performance per watt is a common goal. Thus, the principles of optimizing Energy efficiency by balancing (looking into both and prioritizing the factor which impacts more) computation and data movement can be taken from Eyeriss to other deep learning architectures."
      ],
      "metadata": {
        "id": "OvpxYhvNdg18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.6 Discussion and Critique (10 points):\n",
        "- Are there any assumptions made by the authors that you disagree with or find questionable?\n",
        "- Do you think there are potential improvements or future directions not addressed by the authors?\n",
        "- How would you compare Eyeriss with other architectures or solutions you know of?"
      ],
      "metadata": {
        "id": "cxUpnGmtdjfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.6:\n",
        "Yes there are a few of the assumptions of the author that I disagree with:<br>\n",
        "(1) *Technology:* As stated before in the above points the Eyeriss was implemented in 65nm-CMOS technology and then its results were evaluated. As you go from the higher technology node to current nodes like 3nm, 5nm or 7nm. You see that the power/energy spent due to the switching or activity of data is a becoming a lower factor. While the leakage power/energy consumption is a major concern. So the data gating which was used to reduce these data transfers and read accessess thus reducing the number of changes (switching) in data might not give similar significant improvement. Also at the same time the leakage power spend due to the excessive use of PEs to create that spatial array might become even worse. Thus cutting down on much of the benefits seen. Hence, we need to analyze and try the same technique and evaluate if it still applies with the current technology and if not what changes are needed to get similar results on the latest technology.<br>\n",
        "(2) *Single Chip and only comparison with off-chip DRAM:* Eyeriss is presented as a single chip. In current world scenarios, you have applications of data centers, where multiple chips and accelerators are integrated. For these large scale applications there is no information provided. So how will the Eyeriss integrate with these multiple processors or how will the interconnect behave when communicating with multiple interfaces. As in paper we consider only a DRAM present off-chip and compare the improvement based on the energy/time spent when accessing only that one particular off-chip memory.<br>\n",
        "(3) *Other Factors like Hardware Complexity:* In the paper, author focused on energy efficiency and based on the results over 2 CNNs made the final conclusion of a better solution. We don't have enough knowledge of how did it fare in terms of factors like Hardware Complexity, Cost, Adaptability to different/Emerging deep neural architectures. These factors also play a big role in adapting this solution in the real world.<br>\n",
        "<br> Yes there are several improvements or future directions not addressed in the paper. Namely:<br>\n",
        "(1) *Open Source and Community Development:* As with the recent trend in CPU of taking the open source RISC-V ISA and modify to create your own processor which is thereby helping to boost and maintain the RISC community and also advancing the open source architecture. The author could have proposed a similar item in this domain that by making this architecture open source, they plan to accelerate its evolution by making a community of developers. Which help in it's adaptation to various use cases which it currently lacks as mentioned in the points above.<br>\n",
        "(2) *Other Advanced Architecture Fields:* Applying this concept to other fields and looking into if a similar approach with some tweaks could provide us benefit in other fields like neuromorphic computing, in-memory computing, etc.This might also help in introducing some novel ideas.<br>\n",
        "(3) *Working on other Data Fields:* Similar to the point above, here instead of talking about different fields of advanced architectures. I propose that the author could have approached fields where we have similar huge amount of datas which we have to process using multiple calculations. It will be curious to now change this factor and see the impact. Fields can be like scientific Simulations, Reinforcement Learning, etc.<br>\n",
        "<br> We need to understand before doing the comparison that the use case and the workload on which they work on can be different. Hence the architecture is adjusted post considering these factors. For example, as taught in class the Google's TPU or Nvidia's GPU have their own features and excel in general-purpose AI computing, working on diverse workloads or have a broader ecosystem than the Eyeriss.<br>But Eyeriss is specialized for CNNs, with the focus on energy efficiency and ability to adapt different network shapes it is much more suited for applications where these factors are critical rather than Google's TPU or Nvidia's GPU."
      ],
      "metadata": {
        "id": "cjAQy1qLdvZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.7 Reflection (10 Points):\n",
        "- What was the most surprising or counterintuitive thing you learned from this paper?\n",
        "- How has reading this paper influenced your views on the importance of energy efficiency in deep learning?"
      ],
      "metadata": {
        "id": "hSMCnPg8d_0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.7:\n",
        "The most counterintutive thing that I learned from this paper was that the energy consumed by data movement dominated the energy consumed by data computation. Even though coming from a hardware background, I understand the cost of memory access (latency and power) consumed during this. But I supposed given the vast number of data being read at 1 time through the entire PE array and as we are travelling rest of the time on-chip between the PEs but we have so many multiple computations and those operations. It felt like due to the signifantly high number of computations or operations done on a piece of data. The overall energy/power consumed will tilt in the favor of computation rather than the movement.<br>\n",
        "<br> The paper reinforces the importance of energy efficiency such that it is not just a desirable feature but a fundamental requirement. It highlights that data movement is a major energy consuming aspect and there is a need to develop hardware architectures that are highly efficient in data movement. Also, the fact that even a little effort counts. Data gating on the outlook might seem like a trivial fact but it does have a significant impact on energy efficiency. As, shown in the latest showing of Apple's Wanderlust event where latest set of Iphones were showcased. We know have multiple neural engines running on our mobile phone. This and by extension of introduction of these in domains like IoT energy efficiency is a big factor. They will not be plugged into a power source 24*7*365 like a data center. Moreover, as they run on battery for longer awake time and battery life it is even more significant now that we look into energy efficiency and power consumption associated with deep learning."
      ],
      "metadata": {
        "id": "nBtgEgPXeNR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Turn in your reading assignment by saving this answer sheet back to the Github repository."
      ],
      "metadata": {
        "id": "mnRyd9Iie6Dz"
      }
    }
  ]
}